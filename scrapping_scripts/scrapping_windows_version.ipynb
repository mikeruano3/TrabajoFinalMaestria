{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# this cell is tagged 'parameters'\n",
    "word_to_search = 'Jimmy Morales'\n",
    "question_object = { \"1\": { 'question': '¿qué repercusión tuvo?' },\n",
    "                    \"2\": { 'question': '¿Quién estuvo implicado?' },\n",
    "                    \"3\": { 'question': '¿Corrupción?' }\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loguearse a El Periodico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://elperiodico.com.gt/politica/justicia/2022/08/12/the-economist-jose-ruben-zamora-ha-hecho-una-cruzada-contra-la-corrupcion-en-guatemala/'\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = BeautifulSoup(r.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(s.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By as By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.141.0\n",
      "2.9.0\n",
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import selenium, keras, tensorflow\n",
    "print(selenium.__version__)\n",
    "print(keras.__version__)\n",
    "print(tensorflow.__version__)\n",
    "## pip install selenium==3.141.0\n",
    "## pip install keras==2.9.0\n",
    "## pip install tensorflow==2.9.1\n",
    "## pip install chromedriver-binary\n",
    "## pip install -q transformers\n",
    "## conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path='../chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    botonCerrarNotificacion = driver.find_element_by_xpath('//*[@id=\"onesignal-slidedown-cancel-button\"]' )\n",
    "    botonCerrarNotificacion.click()\n",
    "except:\n",
    "    print('No hay notificacion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_login = driver.find_element_by_xpath('//*[@id=\"userbox\"]/nav/a[2]/i')\n",
    "button_login.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si necesita ingresar usuario y contraseña para ver mas articiulos\n",
    "user_name = driver.find_element_by_xpath('//*[@id=\"user_login\"]')\n",
    "user_password = driver.find_element_by_xpath('//*[@id=\"user_pass\"]')\n",
    "button_accept = driver.find_element_by_xpath('//*[@id=\"wp-submit\"]')\n",
    "user_name.clear()\n",
    "user_password.clear()\n",
    "user_name.send_keys('yoentroalau@gmail.com')\n",
    "user_password.send_keys('A@@@1234')\n",
    "button_accept.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(f'https://elperiodico.com.gt/?s={word_to_search}&Submit=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    entradas_anteriores = driver.find_element_by_class_name('nav-previous')\n",
    "    entradas_anteriores.click()\n",
    "except:\n",
    "    print('No hay entradas anteriores')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_articulo = driver.find_element_by_xpath('//*[@id=\"seccion\"]/div[1]/div/a[1]')\n",
    "link_articulo.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MP pide desestimar investigación que vincula a Jimmy Morales\n",
      "['14-09-21']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "title = driver.find_element_by_class_name('post-title-big').text\n",
    "print(title)\n",
    "date  = driver.find_element_by_xpath('//*[@id=\"space-meta\"]').text\n",
    "formatted_date = re.findall(\"\\d\\d-\\d\\d-\\d\\d\", date)\n",
    "print(formatted_date)\n",
    "\n",
    "articles_body = driver.find_element_by_xpath('//div[@class=\"flexible-article-content\"]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Fiscalía contra la Corrupción solicitó al Juzgado Octavo Penal desestimar la investigación que se había iniciado por la supuesta compra irregular de los aviones Pampa lll a Argentina y que vinculaba al expresidente Jimmy Morales. \n",
      "El juzgado programó la diligencia para discutir la petición de la fiscalía el 22 de febrero de 2022. En la audiencia el Ministerio Público (MP) debe argumentar la razón por la que desiste de continuar con ese caso. \n",
      "Según el MP, no existen medios que ameriten perseguir a ninguna persona, ya que se investigaba la posible compra de las aeronaves, pero al no concretarse, no hay hechos que indagar. “En los medios de investigación se establece que no hay hecho punible que proseguir”, afirmó el ente investigador.\n",
      "Este caso se originó el 2 de julio de 2019. Morales junto con el exministro de la Defensa, Luis Ralda, y la exministra de Relaciones Exteriores, Sandra Jovel, viajaron a Argentina a reunirse con el presidente de esa nación, Mauricio Macri, para concretar la negociación de la compra de los aviones.\n",
      "La adquisición de las aeronaves iba a tener un costo de US$28 millones. Este es otro proceso que el MP no seguirá contra el exmandatario, hace dos meses no apeló el rechazo de un antejuicio interpuesto contra dicho exfuncionario. \n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "articles = articles_body.find_elements(By.TAG_NAME, 'p')\n",
    "\n",
    "full_text = ''\n",
    "\n",
    "for article in articles:\n",
    "    print(article.text)\n",
    "    full_text = full_text + article.text + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/config.json from cache at C:\\Users\\miguel/.cache\\huggingface\\transformers\\17330f67d8c327c0b1699be552404022f63be5db79858b26484fc847da416eb9.2e4532ea7d3ba93d791168876c978107ea0cba47d2b0736de7c9139e9670eff4\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/vocab.txt from cache at C:\\Users\\miguel/.cache\\huggingface\\transformers\\2c511a62e569bb7e3623cdadba0823aa6ac3953d13dc7401f40a47794cea3079.dafbd6e6622cfaafea54bfe717b14fcacdaa069149af8fae4086afa5a9629ec3\n",
      "loading file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/special_tokens_map.json from cache at C:\\Users\\miguel/.cache\\huggingface\\transformers\\9ee3712830b330cf2407b46bba34b1ca9dbeab6c887b79991d4053ca40501c8f.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/tokenizer_config.json from cache at C:\\Users\\miguel/.cache\\huggingface\\transformers\\4d0cfa842922c935f9584d98c1de673525620c32f5749db976f4dd568d90bc76.f57c45f436182a8fb3a56f7b1c341ed2943046fed9922b6963a46c869a9196aa\n",
      "loading configuration file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/config.json from cache at C:\\Users\\miguel/.cache\\huggingface\\transformers\\17330f67d8c327c0b1699be552404022f63be5db79858b26484fc847da416eb9.2e4532ea7d3ba93d791168876c978107ea0cba47d2b0736de7c9139e9670eff4\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/config.json from cache at C:\\Users\\miguel/.cache\\huggingface\\transformers\\17330f67d8c327c0b1699be552404022f63be5db79858b26484fc847da416eb9.2e4532ea7d3ba93d791168876c978107ea0cba47d2b0736de7c9139e9670eff4\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/config.json from cache at C:\\Users\\miguel/.cache\\huggingface\\transformers\\17330f67d8c327c0b1699be552404022f63be5db79858b26484fc847da416eb9.2e4532ea7d3ba93d791168876c978107ea0cba47d2b0736de7c9139e9670eff4\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/pytorch_model.bin from cache at C:\\Users\\miguel/.cache\\huggingface\\transformers\\7966a0423b1c913c4e68d5399e17e4296eb2a7445564ae9ec574ae547efbe8bd.14d8bb83a1f0f787ccc04af18ea2125ec4a26e94474747d8b5834fb315e2caa4\n",
      "All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "All the weights of BertForQuestionAnswering were initialized from the model checkpoint at mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\")\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator = pipeline('text-generation', model='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/config.json from cache at C:\\Users\\miguel/.cache\\huggingface\\transformers\\17330f67d8c327c0b1699be552404022f63be5db79858b26484fc847da416eb9.2e4532ea7d3ba93d791168876c978107ea0cba47d2b0736de7c9139e9670eff4\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/config.json from cache at C:\\Users\\miguel/.cache\\huggingface\\transformers\\17330f67d8c327c0b1699be552404022f63be5db79858b26484fc847da416eb9.2e4532ea7d3ba93d791168876c978107ea0cba47d2b0736de7c9139e9670eff4\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/pytorch_model.bin from cache at C:\\Users\\miguel/.cache\\huggingface\\transformers\\7966a0423b1c913c4e68d5399e17e4296eb2a7445564ae9ec574ae547efbe8bd.14d8bb83a1f0f787ccc04af18ea2125ec4a26e94474747d8b5834fb315e2caa4\n",
      "All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "All the weights of BertForQuestionAnswering were initialized from the model checkpoint at mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n",
      "loading configuration file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/config.json from cache at C:\\Users\\miguel/.cache\\huggingface\\transformers\\17330f67d8c327c0b1699be552404022f63be5db79858b26484fc847da416eb9.2e4532ea7d3ba93d791168876c978107ea0cba47d2b0736de7c9139e9670eff4\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/vocab.txt from cache at C:\\Users\\miguel/.cache\\huggingface\\transformers\\2c511a62e569bb7e3623cdadba0823aa6ac3953d13dc7401f40a47794cea3079.dafbd6e6622cfaafea54bfe717b14fcacdaa069149af8fae4086afa5a9629ec3\n",
      "loading file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/special_tokens_map.json from cache at C:\\Users\\miguel/.cache\\huggingface\\transformers\\9ee3712830b330cf2407b46bba34b1ca9dbeab6c887b79991d4053ca40501c8f.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/tokenizer_config.json from cache at C:\\Users\\miguel/.cache\\huggingface\\transformers\\4d0cfa842922c935f9584d98c1de673525620c32f5749db976f4dd568d90bc76.f57c45f436182a8fb3a56f7b1c341ed2943046fed9922b6963a46c869a9196aa\n",
      "loading configuration file https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/resolve/main/config.json from cache at C:\\Users\\miguel/.cache\\huggingface\\transformers\\17330f67d8c327c0b1699be552404022f63be5db79858b26484fc847da416eb9.2e4532ea7d3ba93d791168876c978107ea0cba47d2b0736de7c9139e9670eff4\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\n",
    "'question-answering',\n",
    "model='mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es',\n",
    "tokenizer=(\n",
    "'mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es',\n",
    "{\"use_fast\": False}\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question_id in question_object:\n",
    "    question_text = question_object[question_id]['question']\n",
    "    question_response = nlp({\n",
    "    'question': question_text,\n",
    "    'context': full_text\n",
    "    })\n",
    "    question_object[question_id]['response'] = question_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": [
     "output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'question': '¿qué repercusión tuvo?', 'response': {'score': 0.24599449336528778, 'start': 771, 'end': 790, 'answer': '2 de julio de 2019.'}}, '2': {'question': '¿Quién estuvo implicado?', 'response': {'score': 0.3930230438709259, 'start': 218, 'end': 233, 'answer': 'Jimmy Morales.'}}, '3': {'question': '¿Corrupción?', 'response': {'score': 0.1715848445892334, 'start': 3, 'end': 32, 'answer': 'Fiscalía contra la Corrupción'}}}\n"
     ]
    }
   ],
   "source": [
    "#this cell is tagged as output\n",
    "print(question_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliografia\n",
    "https://stackoverflow.com/questions/51046454/how-can-we-use-selenium-webdriver-in-colab-research-google-com\n",
    "\n",
    "https://github.com/nteract/papermill\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "257006080e833d260a997c02fb943a84f893968567ef79dcf54106ad401e7e3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
